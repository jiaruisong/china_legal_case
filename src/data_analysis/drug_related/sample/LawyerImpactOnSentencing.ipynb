{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName(\"DrugCrimeAnalysis\").getOrCreate()\n",
    "\n",
    "# Load data\n",
    "df = spark.read.csv(\"/path/to/your/csvfile.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Define the bucketizer\n",
    "splits = list(range(0, int(df.agg({\"TotalImprisonmentLengthforCriminalA\": \"max\"}).collect()[0][0]) + 3, 3))\n",
    "bucketizer = Bucketizer(splits=splits, inputCol=\"TotalImprisonmentLengthforCriminalA\", outputCol=\"ImprisonmentLengthBucket\")\n",
    "\n",
    "# Transform the data\n",
    "df_binned = bucketizer.transform(df)\n",
    "\n",
    "# Group by lawyer status and imprisonment length bucket, then count\n",
    "result_df = df_binned.groupBy(\"lawyer\", \"ImprisonmentLengthBucket\").count()\n",
    "\n",
    "# Convert the result to Pandas DataFrame for plotting (if the dataset is small enough)\n",
    "result_pandas = result_df.toPandas()\n",
    "\n",
    "# Plot using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "for label, grp in result_pandas.groupby('lawyer'):\n",
    "    grp.plot(x='ImprisonmentLengthBucket', y='count', ax=ax, label=label, kind='bar')\n",
    "plt.title('Histogram of Imprisonment Length by Lawyer Presence')\n",
    "plt.xlabel('Imprisonment Length (months)')\n",
    "plt.ylabel('Number of Cases')\n",
    "plt.xticks(ticks=range(len(splits)-1), labels=[f\"{splits[i]}-{splits[i+1]}\" for i in range(len(splits)-1)])\n",
    "plt.legend(title='Lawyer Present')\n",
    "plt.show()\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
