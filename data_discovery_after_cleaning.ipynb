{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Aggregation by Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"AggregateCases\").getOrCreate()\n",
    "\n",
    "# Base path for reading and saving data\n",
    "read_base_path = \"mnt/processed_data_criminal_case_analysis/drug_related_DrugTypeAmount_Penalty_Location_DataframeAlignment_March_20\"\n",
    "save_base_path = \"/mnt/processed_data_criminal_case_analysis/finetuning_training_data/aggregated_data\"\n",
    "\n",
    "\n",
    "# Iterate over each cause of action to read the saved DataFrames, combine them, and write back to a single CSV\n",
    "for cause, output_suffix in causes_of_action.items():\n",
    "    # Construct the path to read the saved files for the current cause of action\n",
    "    read_path = f\"{read_base_path}/*.csv\"\n",
    "    \n",
    "    # Read the saved data\n",
    "    df = spark.read.csv(read_path, header=True, inferSchema=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrame as a temp view\n",
    "df.createOrReplaceTempView(\"cases_view\")\n",
    "\n",
    "# Execute SQL query to find non-integer values\n",
    "non_integer_values_query = \"\"\"\n",
    "SELECT Province, AVG(TotalImprisonmentLengthforCriminalA) AS AveragePenaltyLength, COUNT(*) AS NumberOfCases\n",
    "FROM cases_view\n",
    "GROUP BY Province\n",
    "ORDER BY AveragePenaltyLength DESC;\n",
    "\"\"\"\n",
    "\n",
    "non_integer_values = spark.sql(non_integer_values_query)\n",
    "\n",
    "# Show the results\n",
    "non_integer_values.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
