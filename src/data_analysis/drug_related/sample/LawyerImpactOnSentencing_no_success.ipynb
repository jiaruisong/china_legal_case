{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ad02003-0ed2-465c-8570-24c40781394f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a734084-b235-42b4-b5fd-d89eb30d78ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, BooleanType, FloatType, IntegerType\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName(\"DrugCrimeAnalysis\").getOrCreate()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"OriginalLink\", StringType(), True),\n",
    "    StructField(\"CaseNumber\", StringType(), True),\n",
    "    StructField(\"CaseName\", StringType(), True),\n",
    "    StructField(\"Court\", StringType(), True),\n",
    "    StructField(\"Location\", StringType(), True),\n",
    "    StructField(\"CaseType\", StringType(), True),\n",
    "    StructField(\"TrialProcedure\", StringType(), True),\n",
    "    StructField(\"JudgmentDate\", StringType(), True),\n",
    "    StructField(\"PublicationDate\", StringType(), True),\n",
    "    StructField(\"PartiesInvolved\", StringType(), True),\n",
    "    StructField(\"CausesofAction\", StringType(), True),\n",
    "    StructField(\"LegalBasis\", StringType(), True),\n",
    "    StructField(\"FullText\", StringType(), True),\n",
    "    StructField(\"drug_a\", StringType(), True),\n",
    "    StructField(\"amount_a\", FloatType(), True),\n",
    "    StructField(\"Charge1forCriminalA\", StringType(), True),\n",
    "    StructField(\"FineforCriminalA\", FloatType(), True),\n",
    "    StructField(\"TotalImprisonmentLengthforCriminalA\", IntegerType(), True),\n",
    "    StructField(\"SuspendedforCriminalA\", BooleanType(), True),\n",
    "    StructField(\"Province\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"District\", StringType(), True),\n",
    "    StructField(\"CourtLevel\", StringType(), True),\n",
    "    StructField(\"Adcode\", StringType(), True),\n",
    "    StructField(\"lawyer\", BooleanType(), True),\n",
    "    StructField(\"public_defender\", BooleanType(), True)\n",
    "])\n",
    "\n",
    "# Load data with defined schema OR NOT\n",
    "df = spark.read.csv(\"/mnt/processed_data_criminal_case_analysis/drug_related_data_enrich_cleaning_Apr_15/4_cleaned_data_misalign_exists/\", header=True,\n",
    "                    schema=schema\n",
    "                    )\n",
    "\n",
    "df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d0ce8a9-c5cf-41f8-b659-6694bf74a0e0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# draw distribution of lawyer and non lawyer cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f52f102-e5f7-4f98-89b2-45b0dad4831b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, floor\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert 'lawyer' from boolean to integer for easier processing\n",
    "df = df.withColumn(\"lawyer\", col(\"lawyer\").cast(\"integer\"))\n",
    "\n",
    "# Create bins for the imprisonment lengths\n",
    "df = df.withColumn(\"ImprisonmentBin\", floor(col(\"TotalImprisonmentLengthforCriminalA\") / 3) * 3)\n",
    "\n",
    "# Group by imprisonment bin and lawyer presence, then count\n",
    "df_grouped = df.groupBy(\"ImprisonmentBin\", \"lawyer\").count()\n",
    "\n",
    "# Collect data to Pandas DataFrame for visualization\n",
    "pdf = df_grouped.toPandas()\n",
    "\n",
    "# Pivot the data for plotting\n",
    "pivot_pdf = pdf.pivot(index='ImprisonmentBin', columns='lawyer', values='count').fillna(0)\n",
    "\n",
    "# Set explicit colors for the bars\n",
    "colors = ['red', 'blue']  # Red for cases without a lawyer, Blue for cases with a lawyer\n",
    "\n",
    "# Create the histogram\n",
    "pivot_pdf.plot(kind='bar', stacked=False, figsize=(12, 6), color=colors)\n",
    "plt.title('Histogram of Imprisonment Lengths by Lawyer Presence')\n",
    "plt.xlabel('Imprisonment Length (months)')\n",
    "plt.ylabel('Number of Cases')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(['No Lawyer', 'Lawyer'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8622dec-d987-41c8-babb-6b18679a28cb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# distribution: lawyer, public defender, and non lawyer cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8177c179-32ab-4dcb-b193-94852aa34391",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, floor, when, lit\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Categorize cases based on the type of legal representation\n",
    "df = df.withColumn(\n",
    "    \"Representation\",\n",
    "    when(col(\"lawyer\") & ~col(\"public_defender\"), \"Lawyer\")\n",
    "    .when(col(\"lawyer\") & col(\"public_defender\"), \"Public Defender\")\n",
    "    .when(~col(\"lawyer\"), \"No Representation\")\n",
    ")\n",
    "\n",
    "# Create bins for the imprisonment lengths\n",
    "df = df.withColumn(\"ImprisonmentBin\", floor(col(\"TotalImprisonmentLengthforCriminalA\") / 3) * 3)\n",
    "\n",
    "# Group by imprisonment bin and representation type, then count\n",
    "df_grouped = df.groupBy(\"ImprisonmentBin\", \"Representation\").count()\n",
    "\n",
    "# Collect the data to a Pandas DataFrame for visualization\n",
    "pdf = df_grouped.toPandas()\n",
    "\n",
    "# Pivot the data for plotting\n",
    "pivot_pdf = pdf.pivot(index='ImprisonmentBin', columns='Representation', values='count').fillna(0)\n",
    "\n",
    "# Plotting\n",
    "# Set the colors for each representation category\n",
    "colors = ['#1f77b4', '#2ca02c', '#d62728']  # Blue for 'Lawyer', Green for 'Public Defender', Red for 'No Representation'\n",
    "\n",
    "# Create the stacked bar chart\n",
    "pivot_pdf.plot(kind='bar', stacked=True, color=colors, figsize=(12, 6))\n",
    "\n",
    "# Customize the plot with a grid, axis labels, and title\n",
    "plt.title('Number of Cases by Imprisonment Length and Legal Representation', fontsize=14)\n",
    "plt.xlabel('Imprisonment Length (months)', fontsize=12)\n",
    "plt.ylabel('Number of Cases', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, linestyle='--', which='major', color='grey', alpha=0.5)\n",
    "\n",
    "# Enhance the legend\n",
    "plt.legend(title='Legal Representation', title_fontsize='13')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87d1f07b-53c9-458a-bbc1-f176b16ba9d6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# data cleaning: investigating misalignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5434329a-5aad-4432-8ab4-c7a35b84543a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_filtered_12000 = df.filter(col(\"TotalImprisonmentLengthforCriminalA\")>9999.0)\n",
    "df_filtered_12000.show()\n",
    "\n",
    "df_filtered_12000.write.csv(\"/mnt/processed_data_criminal_case_analysis/drug_related_data_enrich_cleaning_Apr_15/inspect_misalignment_12000.csv\", header=True)\n",
    "\n",
    "# If needed, count these rows to see how many there are\n",
    "count_of_non_numeric_rows = df_filtered_12000.count()\n",
    "print(f\"Number of rows with larger than 9999 on TotalImprisonmentLengthforCriminalA: {count_of_non_numeric_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b6893f5-f10f-46fd-9ce2-bc64463fc9eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#inspect misalignment - 陕西省\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Assuming SparkSession is already started and DataFrame df is available\n",
    "# Uncomment the following line if you need to start a Spark session\n",
    "# spark = SparkSession.builder.appName(\"DrugCrimeAnalysis\").getOrCreate()\n",
    "\n",
    "# Filter DataFrame where TotalImprisonmentLengthforCriminalA equals '陕西省'\n",
    "rows_with_issue = df.filter(col(\"TotalImprisonmentLengthforCriminalA\") == '陕西省')\n",
    "\n",
    "# Show the results\n",
    "rows_with_issue.show(truncate=False)\n",
    "\n",
    "# If needed, you can also count these rows\n",
    "count_of_issue_rows = rows_with_issue.count()\n",
    "print(f\"Number of rows with TotalImprisonmentLengthforCriminalA as '陕西省': {count_of_issue_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91636ba0-dc2b-42c6-9871-2550b6d138cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# inspect misalignment - non numeric value\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, isnan, regexp_extract\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "\n",
    "# Using regexp_extract to find non-numeric values; we consider valid numbers both integers and floats\n",
    "non_numeric_rows = df.filter(regexp_extract(col(\"TotalImprisonmentLengthforCriminalA\"), \"^[+-]?((\\d+(\\.\\d*)?)|(\\.\\d+))([eE][+-]?\\d+)?$\", 0) == \"\")\n",
    "\n",
    "\n",
    "# Show the results\n",
    "# Write non-numeric rows to a CSV file\n",
    "non_numeric_rows.write.csv(\"/mnt/processed_data_criminal_case_analysis/drug_related_data_enrich_cleaning_Apr_15/inspect_misalignment.csv\", header=True)\n",
    "\n",
    "# If needed, count these rows to see how many there are\n",
    "count_of_non_numeric_rows = non_numeric_rows.count()\n",
    "print(f\"Number of rows with non-numeric TotalImprisonmentLengthforCriminalA: {count_of_non_numeric_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5d0149b-40b8-47e7-bce4-bf3995960514",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "LawyerImpactOnSentencing_no_success",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
