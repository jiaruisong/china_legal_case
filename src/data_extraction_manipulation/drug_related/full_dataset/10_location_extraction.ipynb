{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cf8a522-74e4-414f-ae95-3c0009ae7251",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68b76fa9-a138-4649-9b26-cae855200fe4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyahocorasick in /Users/jiaruisong/anaconda3/lib/python3.11/site-packages (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/jiaruisong/chinese_province_city_area_mapper.git\n",
      "  Cloning https://github.com/jiaruisong/chinese_province_city_area_mapper.git to /private/var/folders/pv/gnjct8s51217skw1p2lmnj9w0000gn/T/pip-req-build-9wgalnfk\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/jiaruisong/chinese_province_city_area_mapper.git /private/var/folders/pv/gnjct8s51217skw1p2lmnj9w0000gn/T/pip-req-build-9wgalnfk\n",
      "  Resolved https://github.com/jiaruisong/chinese_province_city_area_mapper.git to commit 9c5e2fe74f2c9c6568573043bbf5db051e9c0988\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /Users/jiaruisong/anaconda3/lib/python3.11/site-packages (from cpca==0.5.5) (2.0.3)\n",
      "Requirement already satisfied: pyahocorasick in /Users/jiaruisong/anaconda3/lib/python3.11/site-packages (from cpca==0.5.5) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jiaruisong/anaconda3/lib/python3.11/site-packages (from pandas->cpca==0.5.5) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jiaruisong/anaconda3/lib/python3.11/site-packages (from pandas->cpca==0.5.5) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/jiaruisong/anaconda3/lib/python3.11/site-packages (from pandas->cpca==0.5.5) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/jiaruisong/anaconda3/lib/python3.11/site-packages (from pandas->cpca==0.5.5) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jiaruisong/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->cpca==0.5.5) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyahocorasick  # Install known missing dependency first\n",
    "%pip install git+https://github.com/jiaruisong/chinese_province_city_area_mapper.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4050df8-e8d0-479b-81d5-94da8b3067d7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Function: location Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ddebf46-239a-4121-87f2-ff4c15ef8df7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import cpca\n",
    "\n",
    "def location_extraction(location):\n",
    "    df = cpca.transform(location)\n",
    "    \n",
    "    columns_mapping = {\n",
    "        \"省\": \"Province\",\n",
    "        \"市\": \"City\",\n",
    "        \"区\": \"District\",\n",
    "        \"地址\": \"CourtLevel\",\n",
    "        \"adcode\": \"Adcode\"\n",
    "    }\n",
    "\n",
    "    # Renaming the columns\n",
    "    df_renamed = df.rename(columns=columns_mapping)\n",
    "\n",
    "    return df_renamed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd47cdba-5e6b-4c97-bc86-cfa726c4b8be",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f77bee8-48fd-46f9-accc-8a5f5cb25071",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Province  City District CourtLevel  Adcode\n",
      "0      江苏省  None     None     高级人民法院  320000\n",
      "1      湖南省   株洲市      芦淞区       人民法院  430203\n",
      "2      湖南省  None     None     高级人民法院  430000\n",
      "3      云南省   曲靖市     None     中级人民法院  530300\n",
      "4      湖南省   长沙市     None     中级人民法院  430100\n",
      "5      湖南省   长沙市     None     中级人民法院  430100\n",
      "6      上海市  None     None   第二中级人民法院  310000\n",
      "7  广西壮族自治区   南宁市      江南区       人民法院  450105\n",
      "8      重庆市     县     None       人民法院  500200\n",
      "9      广东省   深圳市      龙岗区       人民法院  440307\n",
      "  Province City District CourtLevel  Adcode\n",
      "0      重庆市    县     None       人民法院  500200\n"
     ]
    }
   ],
   "source": [
    "court_names = [\n",
    "    \"江苏省高级人民法院\",\n",
    "    \"株洲市芦淞区人民法院\",\n",
    "    \"湖南省高级人民法院\",\n",
    "    \"云南省曲靖市中级人民法院\",\n",
    "    \"湖南省长沙市中级人民法院\",\n",
    "    \"湖南省长沙市中级人民法院\",\n",
    "    \"上海市第二中级人民法院\",\n",
    "    \"南宁市江南区人民法院\",\n",
    "    \"不存在县人民法院\",\n",
    "    \"深圳市龙岗区人民法院\"\n",
    "]\n",
    "\n",
    "court_names_1 = [\"不存在县人民法院\"]\n",
    "df = location_extraction(court_names)\n",
    "print(df)\n",
    "df = location_extraction(court_names_1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94597abb-6b0d-42b4-bb8e-00751748fad3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Location Extraction - bunk edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31899c98-5ef1-4fc9-a46d-de8209580048",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_files(base_path, cause):\n",
    "    # Define the output folder for the processed data.\n",
    "    output_folder = \"/Users/jiaruisong/Documents/Coding/INFO 288 Big Data and Development_Data/drug_related_full_dataset_type_amount_cleaned_penalty_lawyer_location\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Loop through all CSV files in the base_path directory\n",
    "    for filename in os.listdir(base_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(base_path, filename)\n",
    "            df = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "            \n",
    "            \n",
    "            # Presumably, 'location_extraction' extracts location data from 'Court' column\n",
    "            address_data = location_extraction(df['Court'].tolist())\n",
    "            address_data.index = df.index\n",
    "            \n",
    "            # Merge the new address data with the original DataFrame\n",
    "            df_enriched = pd.concat([df, address_data], axis=1)\n",
    "            \n",
    "            # Construct the output path and save the processed DataFrame as a new CSV file\n",
    "            output_file_path = os.path.join(output_folder, filename)\n",
    "            df_enriched.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Define the base path for input files\n",
    "base_path = \"/Users/jiaruisong/Documents/Coding/INFO 288 Big Data and Development_Data/drug_related_full_dataset_type_amount_cleaned_penalty_lawyer\"\n",
    "causes_of_action = [\"drug_related\"]\n",
    "\n",
    "# Process files for each cause of action\n",
    "for cause in causes_of_action:\n",
    "    process_files(base_path, cause)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f08e906-ae93-47f4-90cb-9efbba8f0bf8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# testrun: using a small file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e14905a5-0562-404f-9c53-7b5cd6e98298",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process_files(base_path, cause):\n",
    "\n",
    "    # Define the output folder based on the base path and cause\n",
    "    output_folder = f\"/mnt/processed_data_criminal_case_analysis/drug_related_location_extraction_test_run_March_19\"\n",
    "\n",
    "    # Using dbutils.fs.ls to list directories/files\n",
    "    files = dbutils.fs.ls(base_path)\n",
    "\n",
    "    for sub_file in files:\n",
    "        if sub_file.name.endswith(\".csv\"):\n",
    "            # Reading CSV file into DataFrame\n",
    "            # Convert to local file path if necessary\n",
    "            file_path = sub_file.path.replace(\"dbfs:\", \"/dbfs\")\n",
    "            df = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "\n",
    "            # Filter rows where 'TrialProcedure' column contains '一审'\n",
    "            df_filtered = df[df['TrialProcedure'].str.contains('一审', na=False)]\n",
    "\n",
    "            if df_filtered.empty:\n",
    "                print(\n",
    "                    f\"No data after filtering for {sub_file.name}. Moving to the next file.\")\n",
    "                continue\n",
    "\n",
    "            # Call the function with the entire 'court' column as a list\n",
    "            address_data = location_extraction(df_filtered['Court'].tolist())\n",
    "\n",
    "            # Ensure the resulting DataFrame has the same index as the original for correct row alignment\n",
    "            address_data.index = df_filtered.index\n",
    "\n",
    "            # Merge the new address data with the original DataFrame\n",
    "            df_enriched = pd.concat([df_filtered, address_data], axis=1)\n",
    "\n",
    "            # Construct the output path for the enriched CSV file\n",
    "            output_file_path = 'dbfs:' + \\\n",
    "                os.path.join(\n",
    "                    output_folder, f\"{os.path.basename(sub_file.name)}\")\n",
    "\n",
    "            # Save the processed DataFrame to the new CSV file, ensuring the path is in \"/dbfs\" format for local IO\n",
    "            df_enriched.to_csv(output_file_path.replace(\n",
    "                \"dbfs:\", \"/dbfs\"), index=False)\n",
    "\n",
    "\n",
    "# base_path = \"/mnt/processed_data_criminal_case_analysis/finetuning_training_data/drug_related_sample_training_data/\"\n",
    "base_path = \"/mnt/processed_data_criminal_case_analysis/drug_related_DrugTypeAmount_Penalty_March_19/part-00000-tid-560076838174988988-2cd33208-a73b-45e0-a942-97b7f01f5e87-3229-1-c000.csv\"\n",
    "\n",
    "causes_of_action = [\"drug_related\"]\n",
    "\n",
    "for cause in causes_of_action:\n",
    "    total_rows_count, failed_fetch_count, na_in_response_count = 0, 0, 0\n",
    "    process_files(base_path, cause)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "location_extraction",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
