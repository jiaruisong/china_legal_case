{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e37d31e6-1bfd-4798-bdb8-c1319bb94d73",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "option 1: spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bc8901e-1fbf-4033-bdaf-9175166a422a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_path = \"/mnt/processed_data_criminal_case_analysis/drug_related_DrugTypeAmount_Penalty_Location_March_19\"\n",
    "\n",
    "output_path = \"/mnt/processed_data_criminal_case_analysis/drug_related_DrugTypeAmount_Penalty_Location_DataframeAlignment_March_20\"\n",
    "\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Assuming `common_columns` is a list of all columns identified\n",
    "def align_dataframe(df, common_columns):\n",
    "    for col in common_columns:\n",
    "        if col not in df.columns:\n",
    "            df = df.withColumn(col, lit(None))\n",
    "    return df.select(common_columns)\n",
    "\n",
    "common_columns = [\n",
    "    \"OriginalLink\",\n",
    "    \"CaseNumber\",\n",
    "    \"CaseName\",\n",
    "    \"Court\",\n",
    "    \"Location\",\n",
    "    \"CaseType\",\n",
    "    \"TrialProcedure\",\n",
    "    \"JudgmentDate\",\n",
    "    \"PublicationDate\",\n",
    "    \"PartiesInvolved\",\n",
    "    \"CausesofAction\",\n",
    "    \"LegalBasis\",\n",
    "    \"FullText\",\n",
    "    \"drug_a\",\n",
    "    \"amount_a\",\n",
    "    \"drug_b\",\n",
    "    \"amount_b\",\n",
    "    \"drug_c\",\n",
    "    \"amount_c\",\n",
    "    \"ResponseText\",\n",
    "    \"Charge1forCriminalA\",\n",
    "    \"FineforCriminalA\",\n",
    "    \"TotalImprisonmentLengthforCriminalA\",\n",
    "    \"SuspendedforCriminalA\",\n",
    "    \"Charge2forCriminalA\",\n",
    "    \"Charge1forCriminalB\",\n",
    "    \"Charge2forCriminalB\",\n",
    "    \"FineforCriminalB\",\n",
    "    \"TotalImprisonmentLengthforCriminalB\",\n",
    "    \"SuspendedforCriminalB\",\n",
    "    \"Charge1forCriminalC\",\n",
    "    \"Charge2forCriminalC\",\n",
    "    \"FineforCriminalC\",\n",
    "    \"TotalImprisonmentLengthforCriminalC\",\n",
    "    \"SuspendedforCriminalC\",\n",
    "    \"Charge1forCriminalD\",\n",
    "    \"Charge2forCriminalD\",\n",
    "    \"FineforCriminalD\",\n",
    "    \"TotalImprisonmentLengthforCriminalD\",\n",
    "    \"SuspendedforCriminalD\",\n",
    "    \"Charge1forCriminalE\",\n",
    "    \"Charge2forCriminalE\",\n",
    "    \"FineforCriminalE\",\n",
    "    \"TotalImprisonmentLengthforCriminalE\",\n",
    "    \"SuspendedforCriminalE\",\n",
    "    \"Charge1forCriminalF\",\n",
    "    \"Charge2forCriminalF\",\n",
    "    \"FineforCriminalF\",\n",
    "    \"TotalImprisonmentLengthforCriminalF\",\n",
    "    \"SuspendedforCriminalF\",\n",
    "    \"Charge3forCriminalC\",\n",
    "    \"Province\",\n",
    "    \"City\",\n",
    "    \"District\",\n",
    "    \"CourtLevel\",\n",
    "    \"Adcode\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e2e232e-061e-4491-8777-4f50a85b64a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sub_files = dbutils.fs.ls(base_path)\n",
    "\n",
    "for sub_file in sub_files:\n",
    "    if sub_file.name.endswith(\".csv\"):\n",
    "        file_path = sub_file.path\n",
    "        df = spark.read.format(\"csv\") \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"inferSchema\", \"true\") \\\n",
    "            .load(file_path)\n",
    "        df_aligned = align_dataframe(df, common_columns)\n",
    "        df_aligned.write.mode(\"overwrite\").option(\"header\", \"true\").csv(output_path)\n",
    "        \n",
    "        print(f\"Aligned dataframe for {file_path}\")\n",
    "        df_aligned.printSchema()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23491b43-e6a3-4217-a824-517987b8dc70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23119e5d-8bc4-499d-94ad-96e268dbdae3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "option 2: spark sql="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d953034-03a6-4daa-a12a-8cdd8db74871",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the DataFrame as a temp view\n",
    "df.createOrReplaceTempView(\"cases_view\")\n",
    "\n",
    "# Execute SQL query to find non-integer values\n",
    "non_integer_values_query = \"\"\"\n",
    "SELECT OriginalLink, CaseNumber,\tCaseName,\tCourt,\tLocation,\tCaseType,\tTrialProcedure,\tJudgmentDate,PublicationDate, TotalImprisonmentLengthforCriminalA, PartiesInvolved,\tCausesofAction,\tLegalBasis,\tFullText,\tdrug_a,\tamount_a,\tdrug_b,\tamount_b,\tResponseText,\tCharge1forCriminalA\tFineforCriminalA,\tTotalImprisonmentLengthforCriminalA,\tSuspendedforCriminalA,\tCharge2forCriminalA,\tCharge1forCriminalB,\tCharge2forCriminalB\tFineforCriminalB,\tTotalImprisonmentLengthforCriminalB,\tSuspendedforCriminalB,\tProvince,\tCity,\tDistrict,\tCourtLevel,\tAdcode\n",
    "FROM cases_view\n",
    "WHERE CAST(TotalImprisonmentLengthforCriminalA AS INT) IS NULL\n",
    "AND TotalImprisonmentLengthforCriminalA IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "non_integer_values = spark.sql(non_integer_values_query)\n",
    "\n",
    "# Show the results\n",
    "non_integer_values.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33e7a6b8-56ef-498c-846e-7b1f86e32ec9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "# Replace 'TotalImprisonmentLengthforCriminalA' with the actual column name you want to check\n",
    "# Repeat the process for other TotalImprisonmentLength columns as needed\n",
    "\n",
    "# Try casting the column to an integer type\n",
    "df_with_cast = df.withColumn(\"TotalImprisonmentLengthInt\", col(\"TotalImprisonmentLengthforCriminalB\").cast(\"int\"))\n",
    "\n",
    "# Filter to find rows where cast is not successful\n",
    "# This condition checks for nulls in the casted column which indicates unsuccessful casts\n",
    "non_integer_rows = df_with_cast.filter(df_with_cast[\"TotalImprisonmentLengthInt\"].isNull() & ~df_with_cast[\"TotalImprisonmentLengthforCriminalB\"].isNull())\n",
    "\n",
    "# Show the rows with non-integer values\n",
    "non_integer_rows.select(\"TotalImprisonmentLengthforCriminalB\").show(100, truncate=False)\n",
    "#non_integer_rows.show(non_integer_rows.count(), truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cec390ca-a616-470e-a040-e4be391d99a8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "option 3: pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35bc504d-5bfa-4ee9-b77f-015b7a533e2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "all_columns = [\n",
    "    \"OriginalLink\",\n",
    "    \"CaseNumber\",\n",
    "    \"CaseName\",\n",
    "    \"Court\",\n",
    "    \"Location\",\n",
    "    \"CaseType\",\n",
    "    \"TrialProcedure\",\n",
    "    \"JudgmentDate\",\n",
    "    \"PublicationDate\",\n",
    "    \"PartiesInvolved\",\n",
    "    \"CausesofAction\",\n",
    "    \"LegalBasis\",\n",
    "    \"FullText\",\n",
    "    \"drug_a\",\n",
    "    \"amount_a\",\n",
    "    \"drug_b\",\n",
    "    \"amount_b\",\n",
    "    \"Charge1forCriminalA\",\n",
    "    \"FineforCriminalA\",\n",
    "    \"TotalImprisonmentLengthforCriminalA\",\n",
    "    \"SuspendedforCriminalA\",\n",
    "    \"Charge2forCriminalA\",\n",
    "    \"Charge1forCriminalB\",\n",
    "    \"Charge2forCriminalB\",\n",
    "    \"FineforCriminalB\",\n",
    "    \"TotalImprisonmentLengthforCriminalB\",\n",
    "    \"SuspendedforCriminalB\",\n",
    "    \"Province\",\n",
    "    \"City\",\n",
    "    \"District\",\n",
    "    \"CourtLevel\",\n",
    "    \"Adcode\"\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f373494-92c9-44ba-a18f-0c23e79e361f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "check columns are the same before loading to sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "401d00e8-b4bf-48f3-a866-9806627234b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def align_dataframe(base_path, cause):\n",
    "    previous_one = ['this is the first time']\n",
    "\n",
    "    # Using dbutils.fs.ls to list directories/files\n",
    "    files = dbutils.fs.ls(base_path)\n",
    "\n",
    "    for sub_file in files:\n",
    "        if sub_file.name.endswith(\".csv\"):\n",
    "            # Reading CSV file into DataFrame\n",
    "            # Convert to local file path if necessary\n",
    "            file_path = sub_file.path.replace(\"dbfs:\", \"/dbfs\")\n",
    "            df = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "\n",
    "            columns_to_drop = [col for col in df.columns]\n",
    "\n",
    "            are_same_unordered = Counter(columns_to_drop) == Counter(previous_one)\n",
    "\n",
    "            if not are_same_unordered:\n",
    "                print(columns_to_drop)\n",
    "                print(previous_one)\n",
    "\n",
    "            previous_one= columns_to_drop\n",
    "\n",
    "            \n",
    "            #for x in ['A', 'B', 'C', 'D', 'E', 'F']:\n",
    "                #try:\n",
    "                    #print(df[f'TotalImprisonmentLengthforCriminal{x}'].unique())\n",
    "                    #print(file_path)\n",
    "                #except KeyError:\n",
    "                    #continue\n",
    "            \n",
    "\n",
    "\n",
    "base_path = \"mnt/processed_data_criminal_case_analysis/drug_related_DrugTypeAmount_Penalty_Location_DataframeAlignment_March_20\"\n",
    "\n",
    "causes_of_action = [\"drug_related\"]\n",
    "\n",
    "for cause in causes_of_action:\n",
    "    align_dataframe(base_path, cause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8497ce3c-fd63-4a0f-a9d2-c7d4b042dc0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def align_dataframe(base_path, cause):\n",
    "\n",
    "    # Define the output folder based on the base path and cause\n",
    "    output_folder = \"mnt/processed_data_criminal_case_analysis/drug_related_DrugTypeAmount_Penalty_Location_DataframeAlignment_March_20\"\n",
    "\n",
    "    # Using dbutils.fs.ls to list directories/files\n",
    "    files = dbutils.fs.ls(base_path)\n",
    "\n",
    "    for sub_file in files:\n",
    "        if sub_file.name.endswith(\".csv\"):\n",
    "            # Reading CSV file into DataFrame\n",
    "            # Convert to local file path if necessary\n",
    "            file_path = sub_file.path.replace(\"dbfs:\", \"/dbfs\")\n",
    "            df = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "            \n",
    "            #drop columns that are not needed\n",
    "            columns_to_drop = [col for col in df.columns if col not in all_columns]\n",
    "            df = df.drop(columns=columns_to_drop)\n",
    "            \n",
    "            # add missing columns\n",
    "            for column in all_columns:\n",
    "                if column not in df.columns:\n",
    "                    df[column] = None\n",
    "            \n",
    "            #data cleaning\n",
    "            df.dropna(subset=['FullText'], inplace=True)  # Remove rows with NaN in 'FullText'\n",
    "            df = df[df['FullText'] != '']  # Further remove rows where 'FullText' is an empty string\n",
    "\n",
    "            \n",
    "            # replace '无期徒刑' with 9998,\"死刑\" with 9999\n",
    "            for x in ['A', 'B']:\n",
    "                try:\n",
    "                    df.loc[df[f'TotalImprisonmentLengthforCriminal{x}'].str.contains('无期', na=False), f'TotalImprisonmentLengthforCriminal{x}'] = 9998\n",
    "                    df.loc[df[f'TotalImprisonmentLengthforCriminal{x}'].str.contains('死刑', na=False), f'TotalImprisonmentLengthforCriminal{x}'] = 9999\n",
    "                except (KeyError, AttributeError):\n",
    "                    continue\n",
    "\n",
    "\n",
    "            # Construct the output path for the enriched CSV file\n",
    "            output_file_path = 'dbfs:' + \\\n",
    "                os.path.join(\n",
    "                    output_folder, f\"{os.path.basename(sub_file.name)}\")\n",
    "\n",
    "            # Save the processed DataFrame to the new CSV file, ensuring the path is in \"/dbfs\" format for local IO\n",
    "            df.to_csv(output_file_path.replace(\n",
    "                \"dbfs:\", \"/dbfs/\"), index=False)\n",
    "\n",
    "\n",
    "base_path = \"/mnt/processed_data_criminal_case_analysis/drug_related_DrugTypeAmount_Penalty_Location_March_19\"\n",
    "\n",
    "causes_of_action = [\"drug_related\"]\n",
    "\n",
    "for cause in causes_of_action:\n",
    "    align_dataframe(base_path, cause)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7c1ea20-2503-432b-8c58-64c453f989a6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# data cleaning for drug type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68684531-515f-45f4-8c26-d5a95d3d8a5a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## inspect unqiue values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c3bb7af-2046-4a82-ac68-9e4e73b76c56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def align_dataframe(base_path, cause):\n",
    "    # Using dbutils.fs.ls to list directories/files\n",
    "    files = dbutils.fs.ls(base_path)\n",
    "\n",
    "    # Initialize a list to collect all unique values across files\n",
    "    unique_values = []\n",
    "    i = 0\n",
    "\n",
    "    for sub_file in files:\n",
    "        if sub_file.name.endswith(\".csv\"):\n",
    "            # Reading CSV file into DataFrame\n",
    "            # Convert to local file path if necessary\n",
    "            file_path = sub_file.path.replace(\"dbfs:\", \"/dbfs\")\n",
    "            df = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "\n",
    "            i += 1\n",
    "            \n",
    "            for x in ['a', 'b']:\n",
    "                try:\n",
    "                    # Get unique values from the dataframe\n",
    "                    unique_drug_values = df[f'drug_{x}'].unique()\n",
    "                    # Store them in the list\n",
    "                    unique_values.extend(unique_drug_values)\n",
    "                    print(f\"{i}, Unique values for drug_{x} in {file_path}: {unique_drug_values}\")\n",
    "                except KeyError:\n",
    "                    print(\"key error\", x, \"in file path:\", file_path)\n",
    "                    continue\n",
    "    \n",
    "    # Find overall unique values across all files\n",
    "    overall_unique_values = set(unique_values)\n",
    "    print(\"Overall unique values across all files:\", overall_unique_values)\n",
    "\n",
    "\n",
    "base_path = \"mnt/processed_data_criminal_case_analysis/drug_related_DrugTypeAmount_Penalty_Location_DataframeAlignment_March_20\"\n",
    "\n",
    "causes_of_action = [\"drug_related\"]\n",
    "\n",
    "for cause in causes_of_action:\n",
    "    align_dataframe(base_path, cause)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91310ea3-e39d-4c1c-8dde-01824d6db3fb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# data cleaning for drug amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c95313c-aff5-4d2e-b2f0-0b756b60ea47",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## inpsect unique values of drug amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a529383-3f06-4861-ace7-779da58d4b61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def align_dataframe(base_path, cause):\n",
    "    # Using dbutils.fs.ls to list directories/files\n",
    "    files = dbutils.fs.ls(base_path)\n",
    "\n",
    "    # Initialize a list to collect all unique values across files\n",
    "    unique_values = []\n",
    "    i = 0\n",
    "\n",
    "    for sub_file in files:\n",
    "        if sub_file.name.endswith(\".csv\"):\n",
    "            # Reading CSV file into DataFrame\n",
    "            # Convert to local file path if necessary\n",
    "            file_path = sub_file.path.replace(\"dbfs:\", \"/dbfs\")\n",
    "            df = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "            \n",
    "            for x in ['a', 'b']:\n",
    "                try:\n",
    "                    # Get unique values from the dataframe\n",
    "                    unique_drug_values = df[f'amount_{x}'].unique()\n",
    "                    # Store them in the list\n",
    "                    unique_values.extend(unique_drug_values)\n",
    "                    print(f\"{i}, Unique values for amount_{x} in {file_path}: {unique_drug_values}\")\n",
    "                except KeyError:\n",
    "                    print(\"key error\", x, \"in file path:\", file_path)\n",
    "                    continue\n",
    "    \n",
    "    # Find overall unique values across all files\n",
    "    overall_unique_values = set(unique_values)\n",
    "    print(\"Overall unique values across all files:\", overall_unique_values)\n",
    "\n",
    "\n",
    "base_path = \"mnt/processed_data_criminal_case_analysis/drug_related_DrugTypeAmount_Penalty_Location_DataframeAlignment_March_20\"\n",
    "\n",
    "causes_of_action = [\"drug_related\"]\n",
    "\n",
    "for cause in causes_of_action:\n",
    "    align_dataframe(base_path, cause)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6af1c1de-ffa1-41f2-ad05-0a2b6fb00cd7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## drop '克' and remove other values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "068e7138-cbf2-4027-8a3f-3c11179de689",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# replace the values without saving to csv file\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def align_dataframe(base_path, cause):\n",
    "    # Using dbutils.fs.ls to list directories/files\n",
    "    files = dbutils.fs.ls(base_path)\n",
    "\n",
    "    # Initialize a list to collect all unique values across files\n",
    "    unique_values = []\n",
    "    i = 0\n",
    "\n",
    "    for sub_file in files:\n",
    "        if sub_file.name.endswith(\".csv\"):\n",
    "            # Reading CSV file into DataFrame\n",
    "            # Convert to local file path if necessary\n",
    "            file_path = sub_file.path.replace(\"dbfs:\", \"/dbfs\")\n",
    "            df = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "            \n",
    "            for x in ['a', 'b']:\n",
    "                column_name = f'amount_{x}'\n",
    "                try:\n",
    "                    # Clean and transform the amount data\n",
    "                    df[column_name] = df[column_name].apply(clean_amount)\n",
    "                    \n",
    "                    # Get unique values from the cleaned dataframe\n",
    "                    unique_drug_values = df[column_name].unique()\n",
    "                    # Store them in the list\n",
    "                    unique_values.extend(unique_drug_values)\n",
    "                    print(f\"{i}, Cleaned unique values for {column_name} in {file_path}: {unique_drug_values}\")\n",
    "                except KeyError:\n",
    "                    print(\"Key error\", x, \"in file path:\", file_path)\n",
    "                    continue\n",
    "    \n",
    "    # Find overall unique values across all files\n",
    "    overall_unique_values = set(unique_values)\n",
    "    print(\"Overall unique values across all files:\", overall_unique_values)\n",
    "\n",
    "def clean_amount(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    if isinstance(value, str):\n",
    "        value = value.replace('克', '').replace('g', '').strip()\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return pd.NA\n",
    "\n",
    "base_path = \"mnt/processed_data_criminal_case_analysis/drug_related_DrugTypeAmount_Penalty_Location_DataframeAlignment_March_20\"\n",
    "causes_of_action = [\"drug_related\"]\n",
    "\n",
    "for cause in causes_of_action:\n",
    "    align_dataframe(base_path, cause)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e20689b2-b6b1-43e9-9dad-0e5d43868617",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# data cleaning for charge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06205eab-9681-4976-81e0-1af89aff6b2d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## insepct unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d1788fd-cace-46cb-910f-76f0e0332769",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def align_dataframe(base_path, cause):\n",
    "    # Using dbutils.fs.ls to list directories/files\n",
    "    files = dbutils.fs.ls(base_path)\n",
    "\n",
    "    # Dictionary to store unique values by column\n",
    "    unique_values_dict = {}\n",
    "\n",
    "    for sub_file in files:\n",
    "        if sub_file.name.endswith(\".csv\"):\n",
    "            # Reading CSV file into DataFrame\n",
    "            # Convert to local file path if necessary\n",
    "            file_path = sub_file.path.replace(\"dbfs:\", \"/dbfs\")\n",
    "            df = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "\n",
    "            for x in ['A', 'B']:\n",
    "                for i in ['1', '2']:\n",
    "                    column_name = f'Charge{i}forCriminal{x}'\n",
    "                    try:\n",
    "                        # Fetch unique values from the column\n",
    "                        column_unique_values = df[column_name].unique()\n",
    "                        # Add to the unique values dictionary\n",
    "                        if column_name not in unique_values_dict:\n",
    "                            unique_values_dict[column_name] = set(column_unique_values)\n",
    "                        else:\n",
    "                            unique_values_dict[column_name].update(column_unique_values)\n",
    "                        print(f\"Unique values for {column_name} in {file_path}: {column_unique_values}\")\n",
    "                    except KeyError:\n",
    "                        print(f\"Key error: Column {column_name} does not exist in {file_path}\")\n",
    "                        continue\n",
    "\n",
    "    # Print overall unique values for each column\n",
    "    for column_name, values in unique_values_dict.items():\n",
    "        print(f\"Overall unique values for {column_name}: {values}\")\n",
    "\n",
    "\n",
    "\n",
    "base_path = \"mnt/processed_data_criminal_case_analysis/drug_related_DrugTypeAmount_Penalty_Location_DataframeAlignment_March_20\"\n",
    "\n",
    "causes_of_action = [\"drug_related\"]\n",
    "\n",
    "for cause in causes_of_action:\n",
    "    align_dataframe(base_path, cause)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94de1a0b-704f-4c7a-bb30-9323afa955bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# data cleaning for fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0087dcc-aed1-4e0a-b490-661474765529",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## inspect unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4075826-3676-42ba-9bde-cbbe855922be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def align_dataframe(base_path, cause):\n",
    "    # Using dbutils.fs.ls to list directories/files\n",
    "    files = dbutils.fs.ls(base_path)\n",
    "\n",
    "    for sub_file in files:\n",
    "        if sub_file.name.endswith(\".csv\"):\n",
    "            # Reading CSV file into DataFrame\n",
    "            # Convert to local file path if necessary\n",
    "            file_path = sub_file.path.replace(\"dbfs:\", \"/dbfs\")\n",
    "            df = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "            \n",
    "            for x in ['A', 'B']:\n",
    "                try:\n",
    "                    print(df[f'FineforCriminal{x}'].unique())\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "\n",
    "base_path = \"mnt/processed_data_criminal_case_analysis/drug_related_DrugTypeAmount_Penalty_Location_DataframeAlignment_March_20\"\n",
    "\n",
    "causes_of_action = [\"drug_related\"]\n",
    "\n",
    "for cause in causes_of_action:\n",
    "    align_dataframe(base_path, cause)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79233910-dc63-4a4c-981b-31ad4e3b3401",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# data cleaning for suspened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4494bad-2e07-4359-9002-c9c2b69d0d70",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## inspect unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9804e3b7-247f-402d-bcfc-ac95853e58f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def align_dataframe(base_path, cause):\n",
    "    # Using dbutils.fs.ls to list directories/files\n",
    "    files = dbutils.fs.ls(base_path)\n",
    "\n",
    "    for sub_file in files:\n",
    "        if sub_file.name.endswith(\".csv\"):\n",
    "            # Reading CSV file into DataFrame\n",
    "            # Convert to local file path if necessary\n",
    "            file_path = sub_file.path.replace(\"dbfs:\", \"/dbfs\")\n",
    "            df = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "            \n",
    "            for x in ['A', 'B']:\n",
    "                try:\n",
    "                    print(df[f'SuspendedforCriminal{x}'].unique())\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "\n",
    "base_path = \"mnt/processed_data_criminal_case_analysis/drug_related_DrugTypeAmount_Penalty_Location_DataframeAlignment_March_20\"\n",
    "\n",
    "causes_of_action = [\"drug_related\"]\n",
    "\n",
    "for cause in causes_of_action:\n",
    "    align_dataframe(base_path, cause)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e735f9c0-815b-40fc-9547-4b8bf82dd0d3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## bunk edits suspended to 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acec9892-4c9e-4b94-a888-628571c91439",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data_cleaning",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
