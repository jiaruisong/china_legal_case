{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ae8f9bb-effa-4a24-88ec-d475c986fcd5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Basic Aggregation by Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61528c2e-7c55-4154-a857-31a4b631b025",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"AggregateCases\").getOrCreate()\n",
    "\n",
    "# Base path for reading and saving data\n",
    "read_base_path = \"mnt/processed_data_criminal_case_analysis/drug_related_DrugTypeAmount_Penalty_Location_DataframeAlignment_March_20\"\n",
    "save_base_path = \"/mnt/processed_data_criminal_case_analysis/finetuning_training_data/aggregated_data\"\n",
    "\n",
    "\n",
    "# Iterate over each cause of action to read the saved DataFrames, combine them, and write back to a single CSV\n",
    "\n",
    "    # Construct the path to read the saved files for the current cause of action\n",
    "read_path = f\"{read_base_path}/*.csv\"\n",
    "    \n",
    "    # Read the saved data\n",
    "df = spark.read.csv(read_path, header=True, inferSchema=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8efce2a-230e-4673-8d50-be99ed723ba0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the DataFrame as a temp view\n",
    "df.createOrReplaceTempView(\"cases_view\")\n",
    "\n",
    "# Execute SQL query to find non-integer values\n",
    "non_integer_values_query = \"\"\"\n",
    "SELECT Province, AVG(TotalImprisonmentLengthforCriminalA) AS AveragePenaltyLength, COUNT(*) AS NumberOfCases\n",
    "FROM cases_view\n",
    "GROUP BY Province\n",
    "ORDER BY AveragePenaltyLength DESC;\n",
    "\"\"\"\n",
    "\n",
    "non_integer_values = spark.sql(non_integer_values_query)\n",
    "\n",
    "# Show the results\n",
    "non_integer_values.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e82a4f51-0258-4e17-806d-8e013567d14d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "drug distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "198b24da-53f8-4e7f-a80d-c6790b6a03e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Execute SQL query to find non-integer values\n",
    "non_integer_values_query = \"\"\"\n",
    "SELECT Province, drug_a, AVG(TotalImprisonmentLengthforCriminalA) AS AveragePenaltyLength, COUNT(*) AS NumberOfCases\n",
    "FROM cases_view\n",
    "WHERE drug_a LIKE '%冰毒%' -- This selects records where drug_a contains '冰毒'\n",
    "GROUP BY Province, drug_a\n",
    "ORDER BY AveragePenaltyLength DESC;\n",
    "\"\"\"\n",
    "\n",
    "non_integer_values = spark.sql(non_integer_values_query)\n",
    "\n",
    "# Show the results\n",
    "non_integer_values.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36d91d6b-11b1-4d2a-b401-0907d7becfbf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "penalties over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05ca5eba-ea94-4be8-be74-6e81ea1cc3ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Execute SQL query to find non-integer values\n",
    "non_integer_values_query = \"\"\"\n",
    "SELECT YEAR(JudgmentDate) AS Year, Province, AVG(TotalImprisonmentLengthforCriminalA) AS AveragePenaltyLength, COUNT(*) AS NumberOfCases\n",
    "FROM cases_view\n",
    "GROUP BY YEAR(JudgmentDate), Province\n",
    "ORDER BY Year, Province;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "non_integer_values = spark.sql(non_integer_values_query)\n",
    "\n",
    "# Show the results\n",
    "non_integer_values.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data_discovery_after_cleaning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
