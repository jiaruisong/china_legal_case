{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da17ea3c-76c6-4448-8a62-2a7ce4733a12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def drop_misalign_df(df):\n",
    "    df = df.dropna(subset=['public_defender'])\n",
    "\n",
    "    # List of columns to drop\n",
    "    columns_to_drop = [\n",
    "    'ResponseText_lawyer', 'TrimmedType', 'TextAroundTrimmedPoint', 'ResponseText',\n",
    "    'Charge2forCriminalA', 'Charge1forCriminalB', 'Charge2forCriminalB', \n",
    "    'FineforCriminalB', 'TotalImprisonmentLengthforCriminalB', 'SuspendedforCriminalB', 'drug_b', 'amount_b'\n",
    "    ]\n",
    "    # Drop the columns\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    # Convert empty strings to NaN if not already done\n",
    "    df['amount_a'].replace('', pd.NA, inplace=True)\n",
    "    # Drop rows where 'drug_a' is NaN\n",
    "    df.dropna(subset=['amount_a'], inplace=True)\n",
    "\n",
    "    # Filter DataFrame to keep rows where 'TotalImprisonmentLengthforCriminalA' can be converted to a float\n",
    "    # and check if it's within a specific range, if necessary\n",
    "    # Convert to numeric, coercing errors which will turn non-convertible values into NaN\n",
    "    df['TotalImprisonmentLengthforCriminalA'] = pd.to_numeric(df['TotalImprisonmentLengthforCriminalA'], errors='coerce')\n",
    "\n",
    "    # Drop rows with NaN values in 'TotalImprisonmentLengthforCriminalA' column\n",
    "    df = df.dropna(subset=['TotalImprisonmentLengthforCriminalA'])\n",
    "\n",
    "    # Convert float numbers to int\n",
    "    df['TotalImprisonmentLengthforCriminalA'] = df['TotalImprisonmentLengthforCriminalA'].astype(int)\n",
    "\n",
    "    df = df[(df['TotalImprisonmentLengthforCriminalA'] <= 9999)]\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "def process_files(base_path):\n",
    "    global total_rows_count, failed_fetch_count, na_in_response_count, rows_dropped_count\n",
    "    # Define the output folder based on the base path\n",
    "    output_folder = \"/mnt/processed_data_criminal_case_analysis/drug_related_data_enrich_cleaning_Apr_15/4_cleaned_data_misalign_exists/\"\n",
    "\n",
    "    # Using dbutils.fs.ls to list directories/files\n",
    "    files = dbutils.fs.ls(base_path)\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "        if file.name.endswith(\".csv\"):\n",
    "            # Reading CSV file into DataFrame\n",
    "            file_path = file.path.replace(\"dbfs:\", \"/dbfs\")  # Convert to local file path if necessary\n",
    "            df = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "            total_rows_count += len(df)\n",
    "\n",
    "            # Apply 'trim_and_fetch_facts' function to 'FullText' column\n",
    "            df_misalign_drop = drop_misalign_df(df)\n",
    "\n",
    "            rows_dropped_count += len(df) - len(df_misalign_drop)\n",
    "\n",
    "            if df_misalign_drop.empty:\n",
    "                print(f\"No data after filtering for {file.name}. Moving to the next file.\")\n",
    "                continue\n",
    "            \n",
    "\n",
    "            # Construct the output path for the enriched CSV file\n",
    "            output_file_path = 'dbfs:'+ os.path.join(output_folder, f\"{os.path.basename(file.name)}\")\n",
    "            \n",
    "            # Save the processed DataFrame to the new CSV file, ensuring the path is in \"/dbfs\" format for local IO\n",
    "            df_misalign_drop.to_csv(output_file_path.replace(\"dbfs:\", \"/dbfs\"), index=False)\n",
    "    \n",
    "    return rows_dropped_count\n",
    "\n",
    "\n",
    "base_path = \"/mnt/processed_data_criminal_case_analysis/drug_related_data_enrich_cleaning_Apr_15/2_lawyer_presence_data_enrich/\"\n",
    "\n",
    "total_rows_count, failed_fetch_count, na_in_response_count, rows_dropped_count = 0, 0, 0, 0\n",
    "rows_dropped_count = process_files(base_path)\n",
    "\n",
    "# Print the counts for process failures and rows dropped.\n",
    "print(f\"Total rows processed: {total_rows_count}\")\n",
    "print(f\"Rows dropped: {rows_dropped_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data_cleaning_after_failed_lawyer_plotting",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
