{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a734084-b235-42b4-b5fd-d89eb30d78ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, BooleanType, FloatType, IntegerType\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName(\"DrugCrimeAnalysis\").getOrCreate()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"OriginalLink\", StringType(), True),\n",
    "    StructField(\"CaseNumber\", StringType(), True),\n",
    "    StructField(\"CaseName\", StringType(), True),\n",
    "    StructField(\"Court\", StringType(), True),\n",
    "    StructField(\"Location\", StringType(), True),\n",
    "    StructField(\"CaseType\", StringType(), True),\n",
    "    StructField(\"TrialProcedure\", StringType(), True),\n",
    "    StructField(\"JudgmentDate\", StringType(), True),\n",
    "    StructField(\"PublicationDate\", StringType(), True),\n",
    "    StructField(\"PartiesInvolved\", StringType(), True),\n",
    "    StructField(\"CausesofAction\", StringType(), True),\n",
    "    StructField(\"LegalBasis\", StringType(), True),\n",
    "    StructField(\"FullText\", StringType(), True),\n",
    "    StructField(\"drug_a\", StringType(), True),\n",
    "    StructField(\"amount_a\", FloatType(), True),\n",
    "    StructField(\"drug_b\", StringType(), True),\n",
    "    StructField(\"amount_b\", FloatType(), True),\n",
    "    StructField(\"Charge1forCriminalA\", StringType(), True),\n",
    "    StructField(\"FineforCriminalA\", IntegerType(), True),\n",
    "    StructField(\"TotalImprisonmentLengthforCriminalA\", FloatType(), True),\n",
    "    StructField(\"SuspendedforCriminalA\", BooleanType(), True),\n",
    "    StructField(\"Charge1forCriminalB\", StringType(), True),\n",
    "    StructField(\"FineforCriminalB\", IntegerType(), True),\n",
    "    StructField(\"TotalImprisonmentLengthforCriminalB\", IntegerType(), True),\n",
    "    StructField(\"SuspendedforCriminalB\", BooleanType(), True),\n",
    "    StructField(\"Charge2forCriminalA\", StringType(), True),\n",
    "    StructField(\"Charge2forCriminalB\", StringType(), True),\n",
    "    StructField(\"Province\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"District\", StringType(), True),\n",
    "    StructField(\"CourtLevel\", StringType(), True),\n",
    "    StructField(\"Adcode\", StringType(), True),\n",
    "    StructField(\"TrimmedType\", StringType(), True),\n",
    "    StructField(\"TextAroundTrimmedPoint\", StringType(), True),\n",
    "    StructField(\"lawyer\", BooleanType(), True),\n",
    "    StructField(\"public_defender\", BooleanType(), True)\n",
    "])\n",
    "\n",
    "# Load data with defined schema OR NOT\n",
    "df = spark.read.csv(\"/mnt/processed_data_criminal_case_analysis/drug_related_data_enrich_cleaning_Apr_15/3_drop_ResponseTexts/\", header=True,\n",
    "                    schema=schema\n",
    "                    )\n",
    "\n",
    "df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b37fecdc-659d-4f28-a10c-23bc4a8c9f2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "#DEBUG:\n",
    "\n",
    "# Removing rows where TotalImprisonmentLengthforCriminalA cannot be converted into a float\n",
    "df_filtered = df.filter(col(\"TotalImprisonmentLengthforCriminalA\").cast(\"float\").isNotNull())\n",
    "\n",
    "\n",
    "# Count the number of rows in the filtered DataFrame\n",
    "row_count_filtered = df_filtered.count()\n",
    "\n",
    "print(f\"Total number of rows with non-NULL TotalImprisonmentLengthforCriminalA: {row_count_filtered}\")\n",
    "\n",
    "df_filtered_12000 = df.filter(col(\"TotalImprisonmentLengthforCriminalA\")<=9999.0)\n",
    "df_filtered_12000.show()\n",
    "\n",
    "df_filtered_12000.write.csv(\"/mnt/processed_data_criminal_case_analysis/drug_related_data_enrich_cleaning_Apr_15/inspect_misalignment_12000_temp.csv\", header=True)\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87d1f07b-53c9-458a-bbc1-f176b16ba9d6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# data cleaning: investigating misalignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5434329a-5aad-4432-8ab4-c7a35b84543a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_filtered_12000 = df.filter(col(\"TotalImprisonmentLengthforCriminalA\")>9999.0)\n",
    "df_filtered_12000.show()\n",
    "\n",
    "df_filtered_12000.write.csv(\"/mnt/processed_data_criminal_case_analysis/drug_related_data_enrich_cleaning_Apr_15/inspect_misalignment_12000.csv\", header=True)\n",
    "\n",
    "# If needed, count these rows to see how many there are\n",
    "count_of_non_numeric_rows = df_filtered_12000.count()\n",
    "print(f\"Number of rows with larger than 9999 on TotalImprisonmentLengthforCriminalA: {count_of_non_numeric_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b6893f5-f10f-46fd-9ce2-bc64463fc9eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#inspect misalignment - 陕西省\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Assuming SparkSession is already started and DataFrame df is available\n",
    "# Uncomment the following line if you need to start a Spark session\n",
    "# spark = SparkSession.builder.appName(\"DrugCrimeAnalysis\").getOrCreate()\n",
    "\n",
    "# Filter DataFrame where TotalImprisonmentLengthforCriminalA equals '陕西省'\n",
    "rows_with_issue = df.filter(col(\"TotalImprisonmentLengthforCriminalA\") == '陕西省')\n",
    "\n",
    "# Show the results\n",
    "rows_with_issue.show(truncate=False)\n",
    "\n",
    "# If needed, you can also count these rows\n",
    "count_of_issue_rows = rows_with_issue.count()\n",
    "print(f\"Number of rows with TotalImprisonmentLengthforCriminalA as '陕西省': {count_of_issue_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91636ba0-dc2b-42c6-9871-2550b6d138cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# inspect misalignment - non numeric value\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, isnan, regexp_extract\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "\n",
    "# Using regexp_extract to find non-numeric values; we consider valid numbers both integers and floats\n",
    "non_numeric_rows = df.filter(regexp_extract(col(\"TotalImprisonmentLengthforCriminalA\"), \"^[+-]?((\\d+(\\.\\d*)?)|(\\.\\d+))([eE][+-]?\\d+)?$\", 0) == \"\")\n",
    "\n",
    "\n",
    "# Show the results\n",
    "# Write non-numeric rows to a CSV file\n",
    "non_numeric_rows.write.csv(\"/mnt/processed_data_criminal_case_analysis/drug_related_data_enrich_cleaning_Apr_15/inspect_misalignment.csv\", header=True)\n",
    "\n",
    "# If needed, count these rows to see how many there are\n",
    "count_of_non_numeric_rows = non_numeric_rows.count()\n",
    "print(f\"Number of rows with non-numeric TotalImprisonmentLengthforCriminalA: {count_of_non_numeric_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5d0149b-40b8-47e7-bce4-bf3995960514",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "LawyerImpactOnSentencing_no_success",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
